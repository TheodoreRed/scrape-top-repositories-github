import topic_info
from bs4 import BeautifulSoup
import requests
import pandas as pd

base_url = "https://github.com"
first_topic_page_url = topic_info.topic_links[0]
response = requests.get(first_topic_page_url)
topic_doc = BeautifulSoup(response.text, "html.parser")


username_repo_tags = topic_doc.find_all(
    "h3", {"class": "f3 color-fg-muted text-normal lh-condensed"}
)
a_tags = username_repo_tags[0].find_all("a")
first_username = a_tags[0].text.strip()
first_repo = a_tags[1].text.strip()
first_repo_url = base_url + a_tags[1]["href"]

project_stars = topic_doc.find_all("span", {"class": "Counter js-social-count"})
first_stars = project_stars[0].text

# Given a string number that might end in "k" for thousand
# Returns string as integer
def parse_star_count(star_str):
    star_str = star_str.strip()
    if star_str[-1] == "k":
        return int(float(star_str[0:-1]) * 1000)
    else:
        return int(star_str)


# Returns all the required info about a repository
# h3_tag = result of soup searching a <h3> tag
# star_tag = result of soup searching a <span> tag
def get_repo_info(h3_tag, star_tag):
    a_tags = h3_tag.find_all("a")
    username = a_tags[0].text.strip()
    repo = a_tags[1].text.strip()
    url = base_url + a_tags[1]["href"]
    stars = parse_star_count(star_tag.text.strip())
    return username, repo, url, stars


# print(type(get_repo_info(username_repo_tags[0], project_stars[0])))


topic_repos_dict = {"username": [], "repo_name": [], "repo_url": [], "stars": []}
for i in range(len(username_repo_tags)):
    repo_info = get_repo_info(username_repo_tags[i], project_stars[i])
    topic_repos_dict["username"].append(repo_info[0])
    topic_repos_dict["repo_name"].append(repo_info[1])
    topic_repos_dict["repo_url"].append(repo_info[2])
    topic_repos_dict["stars"].append(repo_info[3])

# topic_repos_df = pd.DataFrame(topic_repos_dict)


def get_topic_page(topic_url):
    # Download the page
    response = requests.get(topic_url)

    # Check download successful
    if response.status_code != 200:
        raise Exception("Failed to load page {}".format(topic_url))

    # Parse using beautiful soup
    topic_doc = BeautifulSoup(response.text, "html.parser")
    return topic_doc


def get_topic_repos(topic_doc):

    # Get h3 tag containing title, repo_url, username
    username_repo_tags = topic_doc.find_all(
        "h3", {"class": "f3 color-fg-muted text-normal lh-condensed"}
    )
    # Get star tags
    project_stars = topic_doc.find_all("span", {"class": "Counter js-social-count"})

    # Get repo information
    topic_repos_dict = {"username": [], "repo_name": [], "repo_url": [], "stars": []}
    for i in range(len(username_repo_tags)):
        repo_info = get_repo_info(username_repo_tags[i], project_stars[i])
        topic_repos_dict["username"].append(repo_info[0])
        topic_repos_dict["repo_name"].append(repo_info[1])
        topic_repos_dict["repo_url"].append(repo_info[2])
        topic_repos_dict["stars"].append(repo_info[3])
    return pd.DataFrame(topic_repos_dict)


doc9 = get_topic_page(topic_info.topic_links[29])
print(get_topic_repos(doc9))
